{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"file-72875f81636342009d1766fa429289eb\",\n",
      "  \"bytes\": 2022,\n",
      "  \"created_at\": 1729518572,\n",
      "  \"filename\": \"batch - StructuredOutputs.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"pending\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-10-01-preview\"\n",
    "    )\n",
    "\n",
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(\n",
    "  file=open(\"batch - StructuredOutputs.jsonl\", \"rb\"), \n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(file.model_dump_json(indent=2))\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track file upload status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-21 14:49:54.541926 File Id: file-72875f81636342009d1766fa429289eb, Status: processed\n"
     ]
    }
   ],
   "source": [
    "# Wait until the uploaded file is in processed state\n",
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"pending\"\n",
    "while status != \"processed\":\n",
    "    time.sleep(15)\n",
    "    file_response = client.files.retrieve(file_id)\n",
    "    status = file_response.status\n",
    "    print(f\"{datetime.datetime.now()} File Id: {file_id}, Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1729518605,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-72875f81636342009d1766fa429289eb\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"validating\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": null,\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1729605005,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": null,\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track batch job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-21 14:51:23.580562 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: validating\n",
      "2024-10-21 14:52:24.030281 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: validating\n",
      "2024-10-21 14:53:24.521352 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: in_progress\n",
      "2024-10-21 14:54:24.951208 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: in_progress\n",
      "2024-10-21 14:55:25.419307 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: in_progress\n",
      "2024-10-21 14:56:25.880283 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: in_progress\n",
      "2024-10-21 14:57:26.330489 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: finalizing\n",
      "2024-10-21 14:58:26.765073 Batch Id: batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107,  Status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"validating\"\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(60)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(f\"{datetime.datetime.now()} Batch Id: {batch_id},  Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine job status details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_6dcbe0ef-1c28-4477-a517-0c59b63ea107\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1729518605,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-72875f81636342009d1766fa429289eb\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"completed\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": 1729519078,\n",
      "  \"error_file_id\": \"file-e0da6ce7-180a-4740-8aaa-caf1dc7d007b\",\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1729605005,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": 1729518991,\n",
      "  \"in_progress_at\": 1729518794,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": \"file-9b0af9ff-1842-4061-9bd7-c521d6fbf45b\",\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 3,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 3\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve batch job output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"custom_id\": \"task-0\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"content\": \"{\\\"BuildingName\\\":\\\"Empire State Building\\\",\\\"HeightInFeet\\\":\\\"1,454\\\",\\\"City\\\":\\\"New York City\\\",\\\"Country\\\":\\\"United States\\\"}\",\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1729518853,\n",
      "      \"id\": \"chatcmpl-AKn9JvRpWcqqqQ9rhlTMoX3Wyybkf\",\n",
      "      \"model\": \"gpt-4o-2024-08-06\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"jailbreak\": {\n",
      "              \"filtered\": false,\n",
      "              \"detected\": false\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": \"fp_d54531d9eb\",\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 27,\n",
      "        \"prompt_tokens\": 82,\n",
      "        \"total_tokens\": 109\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"d1fdb4ef-ef8e-4d52-b06a-0682241b679d\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n",
      "{\n",
      "  \"custom_id\": \"task-1\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"content\": \"{\\\"BuildingName\\\":\\\"The Shard\\\",\\\"HeightInFeet\\\":\\\"1,016\\\",\\\"City\\\":\\\"London\\\",\\\"Country\\\":\\\"United Kingdom\\\"}\",\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1729518853,\n",
      "      \"id\": \"chatcmpl-AKn9JbgY3mngKRwuOstcpy4RnHWyA\",\n",
      "      \"model\": \"gpt-4o-2024-08-06\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"jailbreak\": {\n",
      "              \"filtered\": false,\n",
      "              \"detected\": false\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": \"fp_d54531d9eb\",\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 25,\n",
      "        \"prompt_tokens\": 83,\n",
      "        \"total_tokens\": 108\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"4fedde4e-b1b8-4fa3-a625-3fd94f68fa81\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n",
      "{\n",
      "  \"custom_id\": \"task-2\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"content\": \"{\\\"BuildingName\\\":\\\"Burj Khalifa\\\",\\\"HeightInFeet\\\":\\\"2,717 ft\\\",\\\"City\\\":\\\"Dubai\\\",\\\"Country\\\":\\\"United Arab Emirates\\\"}\",\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1729518853,\n",
      "      \"id\": \"chatcmpl-AKn9JGXD3x2RR9EZyGsCg0QvHEL59\",\n",
      "      \"model\": \"gpt-4o-2024-08-06\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_results\": {\n",
      "            \"jailbreak\": {\n",
      "              \"filtered\": false,\n",
      "              \"detected\": false\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": \"fp_d54531d9eb\",\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 28,\n",
      "        \"prompt_tokens\": 83,\n",
      "        \"total_tokens\": 111\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"7371cb88-b15d-4b0c-972f-318ee94f69f6\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = client.files.content(batch_response.output_file_id)\n",
    "raw_responses = response.text.strip().split('\\n')  \n",
    "\n",
    "for raw_response in raw_responses:  \n",
    "    json_response = json.loads(raw_response)  \n",
    "    formatted_json = json.dumps(json_response, indent=2)  \n",
    "    print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional batch commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancel batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.cancel(\"batch_abc123\") # set to your batch_id for the job you want to cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
